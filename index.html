<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice</title>
  <meta name="description" content="&#39;Website for CVPR 2024 Tutorial &quot;Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice&quot;&#39;">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://cvpr2024-tutorial-low-dim-models.github.io/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice" href="https://cvpr2024-tutorial-low-dim-models.github.io/feed.xml">

  
<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- MathJax -->
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>



<link
  href="https://fonts.googleapis.com"
  rel="preconnect"
  />
<link
  href="https://fonts.gstatic.com"
  rel="preconnect"
  crossorigin="anonymous"
  />
<script
  src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"
  type="text/javascript"
  ></script>
<script type="text/javascript">
  WebFont.load({
    google: {
      families: [
        "Lato:300,300italic,400,400italic,700,700italic",
        "Open Sans:300,300italic,400,400italic,700,700italic",
      ],
    },
  });
</script>

<meta content="https://cvpr2024-tutorial-low-dim-models.github.io/assets/card.png" property="og:image">
<meta content="https://cvpr2024-tutorial-low-dim-models.github.io/assets/card.png" property="twitter:image">
<!-- <meta content="summary_large_image" name="twitter:card"> -->


  
  <meta property="og:title" content="Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice">
  <meta property="og:site_name" content="Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice">
  <meta property="og:url" content="https://cvpr2024-tutorial-low-dim-models.github.io/">
  <meta property="og:description" content="&#39;Website for CVPR 2024 Tutorial &quot;Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice&quot;&#39;">
  
  
  <meta name="twitter:card" content="summary_large_image">
  
  <meta name="twitter:title" content="Learning Deep Low-Dimensional Models from High-Dimensional Data: Fr...">
  <meta name="twitter:description" content="&#39;Website for CVPR 2024 Tutorial &quot;Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory to Practice&quot;&#39;">
  
  

  <link rel="dns-prefetch" href="https://fonts.gstatic.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&amp;display=swap" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">
        <img src="/assets/cvpr_b.svg" alt="CVPR SVG Image" style="display: block; height: 50px;">
    </a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/#overview">Overview</a>
      
        
        <a class="page-link" href="/#speakers">Speakers</a>
      
        
        <a class="page-link" href="/#panelists">Panelists</a>
      
        
        <a class="page-link" href="/#schedule">Schedule</a>
      
        
        <a class="page-link" href="/#materials">Materials</a>
      
    </nav>

  </div>

</header>

    <svg xmlns="http://www.w3.org/2000/svg" class="d-none">
  <symbol id="svg-link" viewBox="0 0 24 24">
  <title>Link</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
    <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
  </svg>
</symbol>

</svg>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
            <center>
<h1>
  
  
    
    Learning Deep Low-Dimensional Models from High-Dimensional Data: From Theory
    to Practice
  
  
  
</h1>
    
<h3 style="color: #44434d">
  
  
    <b>CVPR 2024 Tutorial</b>
  
  
</h3>
    
<h3 style="color: #44434d">
  
  
    
    <b>Date:</b> Tuesday, June 18 (full day tutorial)
  
  
  
</h3>
    
<h3 style="color: #44434d">
  
  
    <b>Location:</b> Room 3 (Summit 442)
  
  
</h3>
    

  <div class="svg-container">
    <!-- Embedding SVG image with <img> tag -->
    <img src="/assets/representation.svg" alt="Representation Learning SVG Image" style="display: block; height: 200px" />
  </div>
</center>
<h2 id="overview">
  
  
    <a href="#overview" class="anchor-heading" aria-labelledby="overview"><svg viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a> Overview
  
  
</h2>
    

<p>Over the past decade, the advent of machine learning and large-scale computing
has immeasurably changed the ways we process, interpret, and predict with data
in imaging and computer vision. The “traditional” approach to algorithm
design, based around parametric models for specific structures of signals and
measurements—say sparse and low-rank models—and the associated optimization
toolkit, is now significantly enriched with data-driven learning-based
techniques, where large-scale networks are pre-trained and then adapted to a
variety of specific tasks. Nevertheless, the successes of both modern
data-driven and classic model-based paradigms rely crucially on correctly
identifying the low-dimensional structures present in real-world data, to the
extent that we see the roles of learning and compression of data processing
algorithms—whether explicit or implicit, as with deep networks—as
inextricably linked.</p>

<p>As such, this tutorial provides a timely tutorial that
uniquely bridges low-dimensional models with deep learning in imaging and
vision. This tutorial will show how:</p>

<ol>
  <li>Low-dimensional models and principles provide a valuable lens for
formulating problems and understanding the behavior of modern deep models in
imaging and computer vision; and how</li>
  <li>Ideas from low-dimensional models can provide valuable guidance for
designing new parameter efficient, robust, and interpretable deep learning
models for computer vision problems in practice.</li>
</ol>

<p>We will begin by introducing
fundamental low-dimensional models (e.g., basic sparse and low-rank models)
with motivating computer vision applications.
Based on these developments, we
will discuss strong conceptual, algorithmic, and theoretical connections
between low-dimensional structures and deep models, providing new perspectives
to understand state-of-the-art deep models in terms of learned representations,
generalizability, and transferability.
Finally, we will demonstrate that these
connections can lead to new principles for designing deep networks learning
low-dimensional structures in computer vision, with both clear interpretability
and practical benefits.
We will conclude with a <strong>panel discussion</strong> with expert researchers from academia
and industry on what role low-dimensional models can and should play in our
current age of opaque large language models and foundation models for computer
vision.</p>
<h2 id="speakers">
  
  
    <a href="#speakers" class="anchor-heading" aria-labelledby="speakers"><svg viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a> Speakers
  
  
</h2>
    

<div style="clear: both; display: flex; flex-wrap: wrap; justify-content:
  space-evenly; ">



<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/sdb.jpg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://sdbuchanan.com/">Sam Buchanan</a></center>
      
    
  
  
</h3>
    
    
    <center><p>TTIC</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/ma.jpeg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a></center>
      
    
  
  
</h3>
    
    
    <center><p>UC Berkeley<br />HKU IDS</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/qq.jpeg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://qingqu.engin.umich.edu/">Qing Qu</a></center>
      
    
  
  
</h3>
    
    
    <center><p>UMichigan</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/yyu.jpg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://yaodongyu.github.io/">Yaodong Yu</a></center>
      
    
  
  
</h3>
    
    
    <center><p>UMD</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/yz.jpg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://sites.google.com/view/yuqianzhang">Yuqian Zhang</a></center>
      
    
  
  
</h3>
    
    
    <center><p>Rutgers</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/zz.jpeg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://zhihuizhu.github.io">Zhihui Zhu</a></center>
      
    
  
  
</h3>
    
    
    <center><p>Ohio State</p></center>
    
    

  </div>
</div>



</div>
<h2 id="panelists">
  
  
    <a href="#panelists" class="anchor-heading" aria-labelledby="panelists"><svg viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a> Panelists
  
  
</h2>
    

<div style="clear: both; display: flex; flex-wrap: wrap; justify-content:
  space-evenly; ">



<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/chen0.jpeg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://www.andrew.cmu.edu/user/beidic/">Beidi Chen</a></center>
      
    
  
  
</h3>
    
    
    <center><p>CMU</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/wc.jpg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://chenwydj.github.io/">Wuyang Chen</a></center>
      
    
  
  
</h3>
    
    
    <center><p>UC Berkeley<br />SFU</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/mj.jpg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://sites.google.com/view/mojan-javaheripi/home">Mojan Javaheripi</a></center>
      
    
  
  
</h3>
    
    
    <center><p>Microsoft Research</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/shen-liyue.jpeg" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://liyueshen.engin.umich.edu/">Liyue Shen</a></center>
      
    
  
  
</h3>
    
    
    <center><p>UMichigan</p></center>
    
    

  </div>
</div>


<div class="organizer" style="width: 102px;">
  
  <img class="organizer-image" src="/assets/images/aw.png" alt="" />
  
  <div>
<h3 class="organizer-name">
  
  
    
      
      <center><a href="https://vita-group.github.io/">Atlas Wang</a></center>
      
    
  
  
</h3>
    
    
    <center><p>UT Austin</p></center>
    
    

  </div>
</div>



</div>
<h2 id="schedule">
  
  
    <a href="#schedule" class="anchor-heading" aria-labelledby="schedule"><svg viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a> Schedule
  
  
</h2>
    

<p>The tutorial will take place on <strong>Tuesday, June 18th</strong>.</p>

<table>
<colgroup>
<col width="69%" />
<col width="17%" />
<col width="14%" />
</colgroup>
<thead>
<tr>
<th>Lecture</th>
<th>Speaker</th>
<th>Time (PT)</th>
</tr>
</thead>
<tbody>
<!-- <tr> -->
<!-- <td class="title" colspan="3" markdown="span"> -->
<!-- **Session 1:** Principles of Basic Low-Dimensional Models -->
<!-- </td> -->
<!-- </tr> -->
<!-- <tr> -->
<!-- <td> -->
<!-- Introduction to Basic Low-Dimensional Models -->
<!-- <br> -->
<!-- <a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a> -->
<!-- <br> -->
<!-- <div class="abstract hidden"> -->
<!-- <p> -->
<!-- The first part will introduce fundamental properties and results for sensing, processing, analyzing, and learning low-dimensional structures from high-dimensional data. We will first discuss classical low-dimensional models, such as sparse coding and low-rank matrix sensing, and motivate these models by applications in computer vision. Based on convex relaxation, we will characterize the conditions, in terms of sample/data complexity, under which the learning problems of recovering such low-dimensional structures become tractable and can be solved efficiently, with guaranteed correctness or accuracy. -->
<!-- </p> -->
<!-- </div> -->
<!-- </td> -->
<!-- <td markdown="span"> -->
<!--   <a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a> -->
<!-- </td> -->
<!-- <td markdown="span"> -->
<!-- 9:00-10:00 -->
<!-- </td> -->
<!-- </tr> -->
<tr>
<td class="title" colspan="3">
<strong>Session 1:</strong> Understanding Low-Dimensional Representations &amp; Learning in Deep Networks
</td>
</tr>
<tr>
<td>
Lecture 1-1: Introduction to Basic Low-Dimensional Models
<br />
<a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a>
<br />
<div class="abstract hidden">
<p>
The first part will introduce fundamental properties and results for sensing, processing, analyzing, and learning low-dimensional structures from high-dimensional data. We will first discuss classical low-dimensional models, such as sparse coding and low-rank matrix sensing, and motivate these models by applications in computer vision. Based on convex relaxation, we will characterize the conditions, in terms of sample/data complexity, under which the learning problems of recovering such low-dimensional structures become tractable and can be solved efficiently, with guaranteed correctness or accuracy.
</p>
</div>
</td>
<td>
  <a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a>
</td>
<td>
9:00-10:00
</td>
</tr>
<tr>
<td>
Lecture 1-2: Understanding Low-Dimensional Representation via Neural Collapse
<br />
<a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a>
<br />
<div class="abstract hidden">
<p>
Continuing, we focus on the strong conceptual connections between low-dimensional structures and deep models in terms of learned representation. We start with the introduction of an intriguing Neural Collapse phenomenon in the last-layer representation and its universality in deep network, and lays out the mathematical foundations of understanding its cause by studying its optimization landscapes. We then generalize and explain this phenomenon and its implications under data imbalancedness. Furthermore, we demonstrate the practical algorithmic implications of Neural Collapse on training deep neural networks.
</p>
</div>
</td>
<td>
  <a href="https://cse.osu.edu/people/zhu.3440">Zhihui Zhu</a>
</td>
<td>
10:00-11:00
</td>
</tr>
<tr>
<td>
Lecture 1-3: Invariant Low-Dimensional Subspaces of Learning Dynamics
<br />
<a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a>
<br />
<div class="abstract hidden">
<p>
We show that low-dimensional structures also emerge in training dynamics of deep networks. Specifically, we show that the evolution of gradient descent only affects a minimal portion of singular vector spaces across all weight matrices. The analysis enables us to considerably improve training efficiency by taking advantage of the low-dimensional structure in learning dynamics. We can construct smaller, equivalent deep linear networks without sacrificing the benefits associated with the wider counterparts. Moreover, it allows us to better understand deep representation learning by elucidating the progressive feature compression and discrimination from shallow to deep layers.
</p>
</div>
</td>
<td>
  <a href="https://qingqu.engin.umich.edu/">Qing Qu</a>
</td>
<td>
11:15-12:15
</td>
</tr>
<tr>
<td class="title" colspan="3">
<strong>Session 2:</strong> Designing Deep Networks for Pursuing Low-Dimensional Structures
</td>
</tr>
<tr>
<td>
Lecture 2-1: Low-Dimensional Representation Learning for High-Dimensional Data via the Principle of Compression
<br />
<a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a>
<br />
<div class="abstract hidden">
<p>
In this part, we will discuss the overall objective of high-dimensional data analysis, that is, learning and transforming the data distribution towards low-dimensional template distributions for downstream tasks (such as linear discriminative representations, expressive mixtures of semantically-meaningful incoherent subspaces), and how it connects to deep representation learning. In particular, we will introduce the principle of maximal coding rate reduction (MCR^2) for learning compact and structured representations. We will discuss how to use MCR^2 as a simple and principled objective to measure the goodness of learned representations. Furthermore, we will discuss the theoretical analysis of the coding reduction objective, including global optima properties and the optimization landscape.
</p>
</div>
</td>
<td>
  <a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a>
</td>
<td>
13:30-14:30
</td>
</tr>
<tr>
<td>
Lecture 2-2: White-Box Architecture Design via Unrolled Optimization and Compression
<br />
<a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a>
<br />
<div class="abstract hidden">
<p>
In this part, we will focus on how to construct white-box deep neural network architectures using unrolled optimization. We will review classical methods such as sparse coding through dictionary learning as particular instantiations of this learning paradigm when the underlying signal model is linear or sparse, along with unrolled optimization as a design principle for white-box deep networks (e.g., LISTA network) that are interpretable ab initio. Next, we will discuss how to construct a white-box deep neural network architecture from the principle of data compression. We will show that the basic iterative gradient ascent scheme for optimizing the rate reduction objective leads to a multi-layer deep network, named ReduNet, which shares common characteristics of modern deep networks such as CNN and ResNet.
</p>
</div>
</td>
<td>
  <a href="https://yaodongyu.github.io/">Yaodong Yu</a> (Yuqian Zhang conflict)
</td>
<td>
14:45-15:45
</td>
</tr>
<tr>
<td>
Lecture 2-3: White-Box Transformers via Sparse Rate Reduction
<br />
<a class="abstract btn btn-sm z-depth-0" role="button" style="color:#959396;">(Lecture Abstract)</a>
<br />
<div class="abstract hidden">
<p>
We demonstrate how combining sparse coding and rate reduction yields sparse linear discriminative representations using an objective called sparse rate reduction. We develop CRATE, a deep network architecture, by unrolling the optimization of this objective and parameterizing feature distribution in each layer. CRATE's operators are mathematically interpretable, with each layer representing an optimization step, making the network a transparent "white box". Remarkably, CRATE closely resembles the transformer architecture, suggesting that the interpretability gained from such networks might also improve our understanding of current, practical deep architectures. Experiments show that CRATE, despite its simplicity, indeed learns to compress and sparsify representations of large-scale real-world image and text datasets. It achieves performance very close to highly engineered transformer-based models. We will also discuss recent results on scaling up such white-box transformers as well as more efficient white-box architecture designs.
</p>
</div>
</td>
<td>
  <a href="https://sdbuchanan.com">Sam Buchanan</a>
</td>
<td>
15:45-16:45
</td>
</tr>
<tr>
<td class="title" colspan="2">
<strong>Session 3:</strong> Panel Discussion
</td>
<td>
17:00-18:00
</td>
</tr>
</tbody>
</table>
<h2 id="materials">
  
  
    <a href="#materials" class="anchor-heading" aria-labelledby="materials"><svg viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a> Materials
  
  
</h2>
    

<p>Slides for the tutorial are available at <a href="https://www.dropbox.com/scl/fo/7m57krmeordlohel4qxye/AKho1GYbOe0AbBlKNzm28Vk?rlkey=le2yuel4ipq50xhzxmyxxczxi&amp;e=3&amp;dl=0">this Dropbox
link</a>.</p>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
       

<!-- <div id="icon-container"> -->
<!--   <div> -->
<!--     <a href=mailto: style="text-decoration: none"> -->
<!--       <img id="icon-container-item" src="/assets/icons/gmail.svg" alt="Mail icon" /> -->
<!--     </a> -->
<!--   </div> -->
<!--   <div> -->
<!--     <a href=https://scholar.google.com/citations?user= style="text-decoration: none"> -->
<!--       <img id="icon-container-item" src="/assets/icons/scholar.svg" alt="Google Scholar icon" /> -->
<!--     </a> -->
<!--   </div> -->
<!---->
<!--   <div> -->
<!--     <a href=https://twitter.com/ -->
<!--        style="text-decoration: none"> -->
<!--       <img id="icon-container-item" src="/assets/icons/twitter.svg" alt="Twitter icon" /> -->
<!--     </a> -->
<!--   </div> -->
<!---->
<!--   <div> -->
<!--     <a href=https://github.com/ -->
<!--        style="text-decoration: none"> -->
<!--       <img id="icon-container-item" src="/assets/icons/github.svg" alt="GitHub icon" /> -->
<!--     </a> -->
<!--   </div> -->
<!-- </div> -->

<div>
  © 2024 <a href="https://sdbuchanan.com">Sam Buchanan</a>,
  <a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a>,
  <a href="https://qingqu.engin.umich.edu/">Qing Qu</a>,
  <a href="https://yaodongyu.github.io/">Yaodong Yu</a>,
  <a href="https://sites.google.com/view/yuqianzhang">Yuqian Zhang</a>,
  <a href="https://cse.osu.edu/people/zhu.3440">Zhihui Zhu</a>
</div>

    </p>

  </div>

</footer>


  </body>

  <!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
